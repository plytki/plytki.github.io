<!DOCTYPE html>
<html lang="pl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Test Teoretyczny z Drzew Decyzyjnych</title>
</head>
<body>
    <h1>Test Teoretyczny z Drzew Decyzyjnych</h1>

    <h2>Pytanie 1</h2>
    <p>Co jest celem przy budowie drzewa decyzyjnego jako regresora?</p>
    <ul>
        <li>a) Minimalizacja entropii rozkładu etykiet klas w regionie</li>
        <li>b) Minimalizacja RSS (sumy kwadratów reszt)</li>
        <li>c) Maksymalizacja liczby podziałów</li>
        <li>d) Redukcja liczby atrybutów</li>
    </ul>

    <h2>Pytanie 2</h2>
    <p>Jaka metoda jest używana do poprawienia jakości modelu drzewa poprzez użycie zespołu drzew?</p>
    <ul>
        <li>a) Pruning</li>
        <li>b) Recursive binary splitting</li>
        <li>c) Bagging</li>
        <li>d) Cross-validation</li>
    </ul>

    <h2>Pytanie 3</h2>
    <p>W metodzie random forest, co oznacza parametr \( m \) w procesie wyboru atrybutów?</p>
    <ul>
        <li>a) Liczbę obserwacji w węźle</li>
        <li>b) Liczbę drzew w lesie</li>
        <li>c) Liczbę losowych atrybutów do rozważenia przy każdym podziale</li>
        <li>d) Minimalną liczbę atrybutów w liściu</li>
    </ul>

    <h2>Pytanie 4</h2>
    <p>Który z poniższych wskaźników jest używany jako miara czystości węzłów w drzewach klasyfikacyjnych?</p>
    <ul>
        <li>a) RSS</li>
        <li>b) Entropia</li>
        <li>c) Gini index</li>
        <li>d) Deviance</li>
    </ul>

    <h2>Pytanie 5</h2>
    <p>Dlaczego metoda "pruning" (przycinanie) może poprawić wydajność drzewa decyzyjnego?</p>
    <ul>
        <li>a) Zwiększa złożoność modelu</li>
        <li>b) Zmniejsza wariancję modelu</li>
        <li>c) Powoduje nadmierne dopasowanie do danych treningowych</li>
        <li>d) Redukuje liczbę atrybutów w modelu</li>
    </ul>

    <h2>Pytanie 6</h2>
    <p>Jaki jest główny cel metody bagging?</p>
    <ul>
        <li>a) Zwiększenie wariancji modelu</li>
        <li>b) Redukcja wariancji modelu</li>
        <li>c) Minimalizacja liczby drzew w modelu</li>
        <li>d) Redukcja liczby atrybutów w modelu</li>
    </ul>

    <h2>Pytanie 7</h2>
    <p>Czym różni się metoda boosting od bagging?</p>
    <ul>
        <li>a) W boostingu drzewa są tworzone niezależnie od siebie</li>
        <li>b) W bagging drzewa są tworzone sekwencyjnie</li>
        <li>c) W boostingu każde drzewo jest tworzone na podstawie informacji z poprzednich drzew</li>
        <li>d) W bagging każde drzewo jest tworzone na losowych podzbiorach danych</li>
    </ul>

    <h2>Pytanie 8</h2>
    <p>Co oznacza parametr \( \alpha \) w procesie cost complexity pruning?</p>
    <ul>
        <li>a) Kontroluje stopień redukcji RSS w każdym podziale</li>
        <li>b) Kontroluje kompromis między złożonością poddrzewa a jego dopasowaniem do danych treningowych</li>
        <li>c) Kontroluje liczbę drzew w lesie losowym</li>
        <li>d) Kontroluje liczbę atrybutów do rozważenia przy każdym podziale</li>
    </ul>

    <h2>Pytanie 9</h2>
    <p>Jakie są główne zalety drzew decyzyjnych?</p>
    <ul>
        <li>a) Są łatwe do interpretacji</li>
        <li>b) Mają najwyższą dokładność predykcji w porównaniu z innymi metodami</li>
        <li>c) Mogą łatwo obsługiwać atrybuty jakościowe bez potrzeby tworzenia zmiennych zastępczych</li>
        <li>d) Zawsze przewyższają modele regresji i klasyfikacji pod względem dokładności</li>
    </ul>

    <h2>Pytanie 10</h2>
    <p>Dlaczego metoda cross-validation jest używana przy wyborze optymalnego poddrzewa?</p>
    <ul>
        <li>a) Aby zminimalizować liczbę podziałów</li>
        <li>b) Aby zmaksymalizować liczbę podziałów</li>
        <li>c) Aby ocenić wydajność modelu na danych testowych</li>
        <li>d) Aby zwiększyć złożoność modelu</li>
    </ul>
</body>
</html>
